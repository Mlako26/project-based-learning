{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyo-lXf8s8kh"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_04_implementacion_arboles-published.ipynb)\n",
        "\n",
        "## Árboles de decisión\n",
        "\n",
        "### Metiendonos debajo del capot\n",
        "\n",
        "En esta notebook exploraremos el funcionamiento de un árbol de decisión construido aquí mismo.\n",
        "\n",
        "Para eso contaremos con algunas partes de código resueltas y otras que se deberán completar.\n",
        "\n",
        "El objetivo será comprender la esencia de cómo se comportan los árboles a medida que le vamos agregando funcionalidad (o introduciendo _bugs_) para entender mejor su funcionamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY0qHtpcs8kl"
      },
      "outputs": [],
      "source": [
        "# Puede ser necesario instalar graphviz\n",
        "#!pip install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oizoWtmys8kn"
      },
      "outputs": [],
      "source": [
        "# Cargamos bibliotecas necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "import operator # Trae los operadores de Python como funciones y no infix\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from graphviz import Digraph\n",
        "import pydotplus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaTJM9dBs8kn"
      },
      "source": [
        "A lo largo de este NoteBook usaremos objetos de distintos tipos de datos. Por simplicidad diremos que en todos los casos usaremos asumiremos que los parámetros pasados para cada función serán de los siguientes tipos:\n",
        "\n",
        "   - el parámetro `instancias` será un `DataFrame` de `pandas`\n",
        "   - el parámetro `etiquetas` será un `array` de `numpy` con valores `'Si'`, `'No'` (mismo para `etiquetas_rama_izquierda` y `etiquetas_rama_derecha`)\n",
        "   - el parámetro `pregunta` será un objeto de la clase `Decision` que es definida en este mismo archivo\n",
        "\n",
        "\n",
        "La clase Árbol la definiremos a continuación. Consta de:\n",
        "\n",
        "   - un constructor\n",
        "   - el método `fit` para entrenarlo (a modo de sklearn)\n",
        "   - el método `predict` para dada una instancia predecir su etiqueta\n",
        "   - el método `score` no se encuentra implementar aún\n",
        "   - métodos para visualizar y explorar el árbol\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LH_cLfjps8ko"
      },
      "outputs": [],
      "source": [
        "# Definición de la clase árbol\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "\n",
        "class Tree:\n",
        "    def __init__(\n",
        "        self,\n",
        "        decision=None,  # Esto va a tener tipo Decision, una clase que vamos a definir más adelante\n",
        "        left: Optional[\"Tree\"] = None,\n",
        "        right: Optional[\"Tree\"] = None,\n",
        "        labels: Optional[np.ndarray] = None,\n",
        "    ):\n",
        "        self.decision = decision\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "        self.data = Counter(labels) if labels is not None else None\n",
        "\n",
        "    def fit(self, instancias: pd.DataFrame, etiquetas: np.ndarray):\n",
        "        # ALGORITMO RECURSIVO para construcción de un árbol de decisión binario.\n",
        "\n",
        "        # Suponemos que estamos parados en la raiz del árbol y tenemos que decidir cómo construirlo.\n",
        "        gain, decision = encontrar_mejor_atributo_y_corte(instancias, etiquetas)\n",
        "\n",
        "        # Criterio de corte: ¿Hay ganancia?\n",
        "        if gain <= 0:\n",
        "            #  Si no hay ganancia en separar, no separamos.\n",
        "            self.data = Counter(etiquetas)\n",
        "        else:\n",
        "            # Si hay ganancia en partir el conjunto en 2\n",
        "            (\n",
        "                instancias_cumplen,\n",
        "                etiquetas_cumplen,\n",
        "                instancias_no_cumplen,\n",
        "                etiquetas_no_cumplen,\n",
        "            ) = partir_segun(decision, instancias, etiquetas)\n",
        "            # partir devuelve instancias y etiquetas que caen en cada rama (izquierda y derecha)\n",
        "\n",
        "            # Paso recursivo (consultar con el computadorX más cercano)\n",
        "            sub_arbol_izquierdo = Tree()\n",
        "            sub_arbol_izquierdo.fit(instancias_cumplen, etiquetas_cumplen)\n",
        "            sub_arbol_derecho = Tree()\n",
        "            sub_arbol_derecho.fit(instancias_no_cumplen, etiquetas_no_cumplen)\n",
        "            # los pasos anteriores crean todo lo que necesitemos de sub-árbol izquierdo y sub-árbol derecho\n",
        "\n",
        "            self.decision = decision\n",
        "            self.left = sub_arbol_izquierdo\n",
        "            self.right = sub_arbol_derecho\n",
        "            self.data = Counter(etiquetas)\n",
        "\n",
        "    def predict(self, x_t: pd.Series) -> str:\n",
        "        if self.decision is None:\n",
        "            if self.data[\"Si\"] > self.data[\"No\"]:\n",
        "                return \"Si\"\n",
        "            else:\n",
        "                return \"No\"\n",
        "        else:\n",
        "            if self.decision.test(x_t):\n",
        "                return self.left.predict(x_t)\n",
        "            else:\n",
        "                return self.right.predict(x_t)\n",
        "\n",
        "    def score(self, X_test: pd.DataFrame, y_test: np.ndarray) -> float:\n",
        "        # COMPLETAR\n",
        "\n",
        "        pass\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return self._imprimir_arbol()\n",
        "\n",
        "    def _imprimir_arbol(self, spacing: str = \"\") -> str:\n",
        "        res = []\n",
        "        if self.decision is None:\n",
        "            res.append(spacing + f\"Hoja: {dict(self.data)}\")\n",
        "        else:\n",
        "            res.append(spacing + f\"{str(self.decision)} - {dict(self.data)}\")\n",
        "\n",
        "        if self.left is not None:\n",
        "            res.append(spacing + \"--> True:\")\n",
        "            res.append(self.left._imprimir_arbol(spacing + \"  \"))\n",
        "\n",
        "        if self.right is not None:\n",
        "            res.append(spacing + \"--> False:\")\n",
        "            res.append(self.right._imprimir_arbol(spacing + \"  \"))\n",
        "\n",
        "        return \"\\n\".join(res)\n",
        "\n",
        "    def render(self) -> Digraph:\n",
        "        dot = Digraph()\n",
        "\n",
        "        self.dot_tree_aux(self, dot, prefix=\"\")\n",
        "\n",
        "        return dot\n",
        "\n",
        "    def dot_tree_aux(self, subtree: \"Tree\", dot: Digraph, prefix: str):\n",
        "        label = [\n",
        "            (\n",
        "                f\"{subtree.decision.feature}: {subtree.decision.value}\"\n",
        "                if subtree.decision is not None\n",
        "                else \"\"\n",
        "            ),\n",
        "            f\"n={sum(subtree.data.values())}\",\n",
        "            str(dict(subtree.data)),\n",
        "        ]\n",
        "        label = \"\\n\".join(label)\n",
        "        col = \"#029E3980\" if subtree.data.most_common(1)[0][0] == \"Si\" else \"#EA080080\"\n",
        "        dot.node(prefix + \"n\", label=label, shape=\"box\", fillcolor=col, style=\"filled\")\n",
        "\n",
        "        if subtree.left:\n",
        "            self.dot_tree_aux(subtree.left, dot, prefix + \"l\")\n",
        "            dot.edge(prefix + \"n\", prefix + \"ln\", label=\"True\")\n",
        "\n",
        "        if subtree.right:\n",
        "            self.dot_tree_aux(subtree.right, dot, prefix + \"r\")\n",
        "            dot.edge(prefix + \"n\", prefix + \"rn\", label=\"False\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myxnwZ2Cs8kp"
      },
      "source": [
        "Para la decisiones en cada nodo tendremos la siguiente clase. Actualmente funciona comparando por igualdad, pero podría ser extendida en el futuro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "53sMugBGs8kp"
      },
      "outputs": [],
      "source": [
        "from typing import Any\n",
        "\n",
        "class Decision:\n",
        "    def __init__(self, feature: str, value: Any, test_function=operator.eq):\n",
        "        self.feature = feature\n",
        "        self.value = value\n",
        "        self.test_function = test_function\n",
        "\n",
        "    def test(self, x: pd.Series) -> bool:\n",
        "        # Devuelve verdadero si la instancia cumple con la pregunta\n",
        "        return self.test_function(self.value, x[self.feature])\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"¿Es el valor para {} igual a {}?\".format(self.feature, self.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdzFFW49s8kq"
      },
      "source": [
        "## Funciones a completar\n",
        "\n",
        "Primero definir la función `gini`, que dado unas etiquetas dan el grado de impureza (ver definición en la teórica), se espera que devuelva un `float`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-gIL3mgis8kq"
      },
      "outputs": [],
      "source": [
        "def gini(etiquetas: np.ndarray) -> float:\n",
        "    # COMPLETAR\n",
        "   etiqueta, count = np.unique(etiquetas, return_counts=True)\n",
        "   impureza = 1\n",
        "   for i in range(etiqueta.size):\n",
        "      impureza -= (count[i]/etiquetas.size)**2\n",
        "\n",
        "   return impureza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TewNEdJVs8kq"
      },
      "source": [
        "Definir la función `ganancia_gini` que dadas ciertas instancias y una posible separación entre dos ramas nos de la mejora que obtendremos al separar de esta manera. Devuelve un `float`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "75upjjE5s8kr"
      },
      "outputs": [],
      "source": [
        "def ganancia_gini(etiquetas_rama_izquierda: np.ndarray, etiquetas_rama_derecha: np.ndarray) -> float:\n",
        "    instanceSize = etiquetas_rama_derecha.size + etiquetas_rama_izquierda.size\n",
        "    leftBranchSize = etiquetas_rama_izquierda / instanceSize\n",
        "    rightBranchSize = etiquetas_rama_derecha / instanceSize\n",
        "    ganancia_gini = gini(np.concatenate((etiquetas_rama_izquierda, etiquetas_rama_derecha))) - gini(etiquetas_rama_izquierda) * leftBranchSize - gini(etiquetas_rama_derecha) * rightBranchSize\n",
        "    return ganancia_gini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T210EwBcs8kr"
      },
      "source": [
        "Definir `partir_segun` que debe separar instancias y etiquetas según si cada instancia cumple o no con condición (ver método `test` de la clase `Decision`).\n",
        "\n",
        "Para este punto se recomienda la utilizacion de máscaras de pandas (ver Notebook 01 - Herramientas).\n",
        "\n",
        "Siguiendo con lo mencionado al inicio del NoteBook, la función debe devolver:\n",
        "\n",
        "   - 2 `DataFrame` de `pandas` con las instancias que cumplen (`instancias_cumplen`) y las que no `instancias_no_cumplen`\n",
        "   - 2 `array` de `numpy` con valores `'Si'`, `'No'`, uno con el valor de la etiqueta para las intancias que cumplen con la pregunta (`etiquetas_cumplen`) y otro con las etiquetas de las que no cumple (`etiquetas_cumplen`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydssuG94s8kr"
      },
      "outputs": [],
      "source": [
        "def partir_segun(\n",
        "    pregunta: Decision,\n",
        "    instancias: pd.DataFrame,\n",
        "    etiquetas: np.ndarray\n",
        ") -> Tuple[pd.DataFrame, np.ndarray, pd.DataFrame, np.ndarray]:\n",
        "    # Esta función debe separar instancias y etiquetas según si cada instancia cumple o no\n",
        "    # COMPLETAR\n",
        "    (instancias_cumplen,\n",
        "         etiquetas_cumplen,\n",
        "         instancias_no_cumplen,\n",
        "         etiquetas_no_cumplen) = [], [], [], []\n",
        "\n",
        "    return instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPyvLLDIs8ks"
      },
      "source": [
        "A continuación se propone una implementación para poder encontrar el mejor atributo y corte posible. Esta función devuelve un `float` y una `Decision` correspondientes al mejor atributo y corte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nenNh4l8s8ks"
      },
      "outputs": [],
      "source": [
        "def encontrar_mejor_atributo_y_corte(\n",
        "    instancias: pd.DataFrame, etiquetas: np.ndarray\n",
        ") -> Tuple[float, Decision]:\n",
        "    # Implementación Gini Gain.\n",
        "    max_ganancia = 0\n",
        "    mejor_pregunta = None\n",
        "    for columna in instancias.columns:\n",
        "        for valor in set(instancias[columna]):\n",
        "            # Probando corte para atributo y valor\n",
        "            pregunta = Decision(columna, valor)\n",
        "            _, etiquetas_rama_izquierda, _, etiquetas_rama_derecha = partir_segun(\n",
        "                pregunta, instancias, etiquetas\n",
        "            )\n",
        "            if len(etiquetas_rama_izquierda) == 0 or len(etiquetas_rama_derecha) == 0:\n",
        "                continue\n",
        "\n",
        "            ganancia = ganancia_gini(etiquetas_rama_izquierda, etiquetas_rama_derecha)\n",
        "\n",
        "            if ganancia > max_ganancia:\n",
        "                max_ganancia = ganancia\n",
        "                mejor_pregunta = pregunta\n",
        "\n",
        "    return max_ganancia, mejor_pregunta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8wFEqIds8ks"
      },
      "source": [
        "Dado el siguiente dataset (el mismo que visto en clase):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjPDzA4zs8ks"
      },
      "outputs": [],
      "source": [
        "X = pd.DataFrame([[\"Sol\",\"Calor\",\"Alta\",\"Debil\"],\n",
        "                [\"Sol\",\"Calor\",\"Alta\",\"Fuerte\"],\n",
        "                [\"Nublado\",\"Calor\",\"Alta\",\"Debil\"],\n",
        "                [\"Lluvia\",\"Templado\",\"Alta\",\"Debil\"],\n",
        "                [\"Lluvia\",\"Frio\",\"Normal\",\"Debil\"],\n",
        "                [\"Lluvia\",\"Frio\",\"Normal\",\"Fuerte\"],\n",
        "                [\"Nublado\",\"Frio\",\"Normal\",\"Fuerte\"],\n",
        "                [\"Sol\",\"Templado\",\"Alta\",\"Debil\"],\n",
        "                [\"Sol\",\"Frio\",\"Normal\",\"Debil\"],\n",
        "                [\"Lluvia\",\"Templado\",\"Normal\",\"Debil\"],\n",
        "                [\"Sol\",\"Templado\",\"Normal\",\"Fuerte\"],\n",
        "                [\"Nublado\",\"Templado\",\"Alta\",\"Fuerte\"],\n",
        "                [\"Nublado\",\"Calor\",\"Normal\",\"Debil\"],\n",
        "                [\"Lluvia\",\"Templado\",\"Alta\",\"Fuerte\"]],\n",
        "                columns = ['Cielo', 'Temperatura', 'Humedad', 'Viento'])\n",
        "\n",
        "y = np.array(['No', 'No', 'Si', 'Si', 'Si', 'No', 'Si', 'No', 'Si', 'Si', 'Si', 'Si', 'Si', 'No'])\n",
        "\n",
        "display(X)\n",
        "display(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afZYnYZxs8ks"
      },
      "source": [
        "Completar las funciones previas, entrenar y visualizar un Árbol de Decisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPfU2R3Ys8kt"
      },
      "outputs": [],
      "source": [
        "arbol = Tree()\n",
        "arbol.fit(X, y)\n",
        "print(arbol)\n",
        "arbol.render()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nQuE31Ns8ku"
      },
      "source": [
        "Para evaluar instancias en el árbol podemos construirlas y evaluarlas de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYzyaLCDs8ku"
      },
      "outputs": [],
      "source": [
        "xs_nuevo = [{'Cielo': 'Sol', 'Temperatura': 'Calor', 'Humedad': 'Alta', 'Viento': 'Debil'},\n",
        "            {'Cielo': 'Nublado', 'Temperatura': 'Calor', 'Humedad': 'Alta', 'Viento': 'Debil'}]\n",
        "\n",
        "for instancia in xs_nuevo:\n",
        "    res = arbol.predict(instancia)\n",
        "    print(f\"Para un día {instancia} obtuve {res}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRKBwKQls8kv"
      },
      "source": [
        "¿Se obtuvieron los valores esperados? Explorar al menos 1 caso por cada rama del árbol."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCjsN_u3s8kv"
      },
      "source": [
        "# Opcional: Atributos continuos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtSqZ2_ds8kv"
      },
      "source": [
        "La implementación anterior permite construir árboles partiendo de un dataset cuyos atributos no son continuos. Modificar dicha implementación para que soporte este tipo de atributos.\n",
        "¿Qué funciones hay que modificar?"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}